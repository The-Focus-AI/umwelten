---
alwaysApply: true
description: Project overview and core architecture for the umwelten AI model evaluation tool
---

# Umwelten - AI Model Evaluation Tool

## Project Overview
Umwelten is a command-line tool for evaluating and comparing AI models across different providers, with a focus on usability, cost transparency, and comprehensive model information. The project implements the "Umwelt" concept - creating a semantic framework around how models perceive and interact with their environment.

## Core Architecture

### Semantic Framework
- **Cognition** (`src/cognition/`): The reasoning and thinking processes (formerly "models")
- **Interaction** (`src/interaction/`): Model-environment interactions (formerly "conversation") 
- **Stimulus** (`src/stimulus/`): Input that triggers cognitive response (formerly "prompt")
- **Umwelt**: The perceptual world model operates within

### Key Directories
- [src/cognition/](mdc:src/cognition/): Model interfaces, runners, and cognitive processes
- [src/interaction/](mdc:src/interaction/): Interaction management and conversation handling
- [src/stimulus/](mdc:src/stimulus/): Stimulus processing and tool integration
- [src/providers/](mdc:src/providers/): AI provider implementations (Google, OpenRouter, Ollama, LM Studio)
- [src/cli/](mdc:src/cli/): Command-line interface implementation
- [src/mcp/](mdc:src/mcp/): Model Context Protocol client and server frameworks
- [src/evaluation/](mdc:src/evaluation/): Model evaluation and scoring framework
- [src/memory/](mdc:src/memory/): Memory store and fact extraction system
- [scripts/](mdc:scripts/): Example implementations and utility scripts

### Tech Stack
- **TypeScript/Node.js** with strict mode
- **Vercel AI SDK** for consistent model interfaces
- **Zod** for schema validation
- **Commander.js** for CLI
- **Vitest** for testing
- **pnpm** for package management

## Critical Implementation Rules
1. **ALWAYS use Vercel AI SDK wrappers** for ALL providers
   - OpenRouter: @openrouter/ai-sdk-provider
   - Google: @ai-sdk/google
   - Ollama: ollama-ai-provider
   - LM Studio: Custom REST API wrapper
2. **NEVER use provider-specific SDKs directly**
3. All providers must implement the `LanguageModelV1` interface from 'ai' package
4. Use TypeScript strict mode and comprehensive type safety
5. Follow the semantic naming convention (Interaction, Stimulus, Cognition)

## Project Memory
- [memory/project-brief.md](mdc:memory/project-brief.md): Complete project overview and goals
- [memory/architecture.md](mdc:memory/architecture.md): Detailed technical architecture
- [memory/active-context.md](mdc:memory/active-context.md): Current development status
- [memory/progress.md](mdc:memory/progress.md): Project progress tracking
- [memory/worklog.md](mdc:memory/worklog.md): Development history and decisions
